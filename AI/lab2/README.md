# Лабораторная №2
В этой лабораторной работе я реализовал 4 алгоритма ML:
1. *Логистическая регрессия:* Стандартная реализация с градиентным спуском. По сравнению с sklearn моя реализация работает на 17.2% менее точно на тестовых данных в 2.223 раза медленнее. Вот все метрики, на которые я ориентировался для этого алгоритма:  

precision: 0.8125709364848686   
recall: 0.7635   
train accuracy: 0.761125   
test accuracy: 0.7635   
execution time: 0.21050920486450195     

2. *K-ближайших соседей:* В данном классе можно задать K, по умолчанию оно равно 5. Расстояние от точки до соседей измеряется как квадрат разностей. И я был приятно удивлён, когда узнал, что моя реализация работает с той же точностью на тестовых данных, что и KNN из sklearn. Правда, на это моей версии требуется почти в 4 раза больше времени.  Метрики для оценки этого алгоритма:  

precision: 0.9736333039542855   
recall: 0.9734999999999999   
train accuracy: 0.9846250000000001   
test accuracy: 0.9735000000000001   
execution time: 0.8632041454315186

Заметно, что точность KNN на моем датасете значительно выше.    

3. *Дерево решений:* Данный алгоритм я реализовал со специальной надстройкой для использования в Случайном лесу, но если вызывать конструктор без параметров, то алгоритм будет работать сам по себе. Для леса я добавил перемешивание признаков с возможным их повторением или отсутсвием и выбором части из них. По сути, это обычное бинарное дерево со специальной функцией /findSplitThreshold/, которая находит оптимальное разбиение по признаку при помощи коэффициента Джини. Данный алгоритм работает быстрее KNN, но проигрывает в точности в моем случае. Эта реализация почти такая-же точная, что и дерево из sklearn, но она в 53.396 раза медленне, и это заметно при запуске кода. Видимо, при посторении дерева, распараллеливание сильно ускоряет процесс, да и строю дерево я не самым оптимальным методом.  

Метрики алгоритма в моем исполнении:  
precision: 0.910410482046418  
recall: 0.909  
train accuracy: 0.916  
test accuracy: 0.909  
execution time: 0.5756097316741944  

4. *Случайный лес:* в этой реализации можно выбрать количество и максимальную высоту деревьев. Я задал 200 деревьев по-умолчанию, чтобы повысить точность и приблизиться к sklearn. В итоге мой случайный лес на 16% менее точный, чем лес из sklearn, А разница в скорости работы вообще космическая: Случайный лес из sklearn работает в 180.155 раз быстрее.  

Метрики Случайного леса:  
precision: 0.8346260164072558  
recall: 0.82  
train accuracy: 0.9286249999999999  
test accuracy: 0.82  
execution time: 114.72256398200989  

Так же Случайный лес в моем исполнении работает даже менее точно, чем мое Дерево решений. Думаю, разницу в скорости можно оставить без комментариев.

## Вывод  
Было интересно реализовать основные алгоритмы ML и как следует разобраться в них в процессе. Очевидно, что после тестирования никто не будет использовать мои реализации, потому что sklearn по всем метрикам лучше, чего я и ожидал. 
